{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.1 \n",
    "Clean up the dataset and create x_train, y_train, x_test, y_test in numpy arrays <br>\n",
    "Provide summary statistics for the training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv('train.csv', header = None)\n",
    "df_test = pd.read_csv('test.csv', header = None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove rows with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/pandas/core/ops/array_ops.py:253: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  res_values = method(rvalues)\n"
     ]
    }
   ],
   "source": [
    "for i in range(15):\n",
    "    df_train = df_train[df_train[i] != ' ?']\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "\n",
    "for i in range(15):\n",
    "    df_test = df_test[df_test[i] != ' ?']\n",
    "df_test = df_test.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create x, y data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train =  df_train[14]\n",
    "y_train = y_train.to_frame()\n",
    "x_train = df_train.copy()\n",
    "del x_train[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30157</th>\n",
       "      <td>27</td>\n",
       "      <td>Private</td>\n",
       "      <td>257302</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Tech-support</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>38</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30158</th>\n",
       "      <td>40</td>\n",
       "      <td>Private</td>\n",
       "      <td>154374</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30159</th>\n",
       "      <td>58</td>\n",
       "      <td>Private</td>\n",
       "      <td>151910</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Widowed</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Unmarried</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30160</th>\n",
       "      <td>22</td>\n",
       "      <td>Private</td>\n",
       "      <td>201490</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>20</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30161</th>\n",
       "      <td>52</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>287927</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Wife</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>15024</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>30162 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0                  1       2            3   4                    5   \\\n",
       "0      39          State-gov   77516    Bachelors  13        Never-married   \n",
       "1      50   Self-emp-not-inc   83311    Bachelors  13   Married-civ-spouse   \n",
       "2      38            Private  215646      HS-grad   9             Divorced   \n",
       "3      53            Private  234721         11th   7   Married-civ-spouse   \n",
       "4      28            Private  338409    Bachelors  13   Married-civ-spouse   \n",
       "...    ..                ...     ...          ...  ..                  ...   \n",
       "30157  27            Private  257302   Assoc-acdm  12   Married-civ-spouse   \n",
       "30158  40            Private  154374      HS-grad   9   Married-civ-spouse   \n",
       "30159  58            Private  151910      HS-grad   9              Widowed   \n",
       "30160  22            Private  201490      HS-grad   9        Never-married   \n",
       "30161  52       Self-emp-inc  287927      HS-grad   9   Married-civ-spouse   \n",
       "\n",
       "                       6               7       8        9      10  11  12  \\\n",
       "0            Adm-clerical   Not-in-family   White     Male   2174   0  40   \n",
       "1         Exec-managerial         Husband   White     Male      0   0  13   \n",
       "2       Handlers-cleaners   Not-in-family   White     Male      0   0  40   \n",
       "3       Handlers-cleaners         Husband   Black     Male      0   0  40   \n",
       "4          Prof-specialty            Wife   Black   Female      0   0  40   \n",
       "...                   ...             ...     ...      ...    ...  ..  ..   \n",
       "30157        Tech-support            Wife   White   Female      0   0  38   \n",
       "30158   Machine-op-inspct         Husband   White     Male      0   0  40   \n",
       "30159        Adm-clerical       Unmarried   White   Female      0   0  40   \n",
       "30160        Adm-clerical       Own-child   White     Male      0   0  20   \n",
       "30161     Exec-managerial            Wife   White   Female  15024   0  40   \n",
       "\n",
       "                   13  \n",
       "0       United-States  \n",
       "1       United-States  \n",
       "2       United-States  \n",
       "3       United-States  \n",
       "4                Cuba  \n",
       "...               ...  \n",
       "30157   United-States  \n",
       "30158   United-States  \n",
       "30159   United-States  \n",
       "30160   United-States  \n",
       "30161   United-States  \n",
       "\n",
       "[30162 rows x 14 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test =  df_test[14]\n",
    "y_test = y_test.to_frame()\n",
    "x_test = df_test.copy()\n",
    "del x_test[14]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>Private</td>\n",
       "      <td>226802</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>89814</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Farming-fishing</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28</td>\n",
       "      <td>Local-gov</td>\n",
       "      <td>336951</td>\n",
       "      <td>Assoc-acdm</td>\n",
       "      <td>12</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Protective-serv</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>160323</td>\n",
       "      <td>Some-college</td>\n",
       "      <td>10</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Machine-op-inspct</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>7688</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>34</td>\n",
       "      <td>Private</td>\n",
       "      <td>198693</td>\n",
       "      <td>10th</td>\n",
       "      <td>6</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Other-service</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15055</th>\n",
       "      <td>33</td>\n",
       "      <td>Private</td>\n",
       "      <td>245211</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15056</th>\n",
       "      <td>39</td>\n",
       "      <td>Private</td>\n",
       "      <td>215419</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15057</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>374983</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15058</th>\n",
       "      <td>44</td>\n",
       "      <td>Private</td>\n",
       "      <td>83891</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Own-child</td>\n",
       "      <td>Asian-Pac-Islander</td>\n",
       "      <td>Male</td>\n",
       "      <td>5455</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15059</th>\n",
       "      <td>35</td>\n",
       "      <td>Self-emp-inc</td>\n",
       "      <td>182148</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>United-States</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15060 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       0              1       2              3   4                    5   \\\n",
       "0      25        Private  226802           11th   7        Never-married   \n",
       "1      38        Private   89814        HS-grad   9   Married-civ-spouse   \n",
       "2      28      Local-gov  336951     Assoc-acdm  12   Married-civ-spouse   \n",
       "3      44        Private  160323   Some-college  10   Married-civ-spouse   \n",
       "4      34        Private  198693           10th   6        Never-married   \n",
       "...    ..            ...     ...            ...  ..                  ...   \n",
       "15055  33        Private  245211      Bachelors  13        Never-married   \n",
       "15056  39        Private  215419      Bachelors  13             Divorced   \n",
       "15057  38        Private  374983      Bachelors  13   Married-civ-spouse   \n",
       "15058  44        Private   83891      Bachelors  13             Divorced   \n",
       "15059  35   Self-emp-inc  182148      Bachelors  13   Married-civ-spouse   \n",
       "\n",
       "                       6               7                    8        9     10  \\\n",
       "0       Machine-op-inspct       Own-child                Black     Male     0   \n",
       "1         Farming-fishing         Husband                White     Male     0   \n",
       "2         Protective-serv         Husband                White     Male     0   \n",
       "3       Machine-op-inspct         Husband                Black     Male  7688   \n",
       "4           Other-service   Not-in-family                White     Male     0   \n",
       "...                   ...             ...                  ...      ...   ...   \n",
       "15055      Prof-specialty       Own-child                White     Male     0   \n",
       "15056      Prof-specialty   Not-in-family                White   Female     0   \n",
       "15057      Prof-specialty         Husband                White     Male     0   \n",
       "15058        Adm-clerical       Own-child   Asian-Pac-Islander     Male  5455   \n",
       "15059     Exec-managerial         Husband                White     Male     0   \n",
       "\n",
       "       11  12              13  \n",
       "0       0  40   United-States  \n",
       "1       0  50   United-States  \n",
       "2       0  40   United-States  \n",
       "3       0  40   United-States  \n",
       "4       0  30   United-States  \n",
       "...    ..  ..             ...  \n",
       "15055   0  40   United-States  \n",
       "15056   0  36   United-States  \n",
       "15057   0  50   United-States  \n",
       "15058   0  40   United-States  \n",
       "15059   0  60   United-States  \n",
       "\n",
       "[15060 rows x 14 columns]"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "x_test.columns = ['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss', 'hours-per-week', 'native-country']\n",
    "binary_col = ['workclass', 'education', 'marital-status', 'occupation', 'relationship', 'race', 'sex', 'native-country']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1-of-K encoding\n",
    "Only keep values that occur more than 10 times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in binary_col:\n",
    "    df2 = pd.get_dummies(x_train[i])\n",
    "    df2_col = df2.columns\n",
    "    for j in df2_col:\n",
    "        df2[j] = df2[j].astype('int8')\n",
    "        sum_col = df2[j].sum()\n",
    "        if sum_col < 10:\n",
    "            del df2[j]\n",
    "    x_train = x_train.join(df2)\n",
    "    del x_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_col = x_train.columns\n",
    "for i in binary_col:\n",
    "    df2 = pd.get_dummies(x_test[i])\n",
    "    x_test = x_test.join(df2)\n",
    "    del x_test[i]\n",
    "test_col = x_test.columns\n",
    "for i in test_col:\n",
    "    if i not in train_col:\n",
    "        del x_test[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = y_train.replace(' <=50K', 0)\n",
    "y_train = y_train.replace(' >50K', 1)\n",
    "y_test = y_test.replace(' <=50K.', 0)\n",
    "y_test = y_test.replace(' >50K.', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train has 30162 observations and 102 columns\n",
      "summary of continuous features\n",
      "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
      "count  30162.000000  3.016200e+04   30162.000000  30162.000000  30162.000000   \n",
      "mean      38.437902  1.897938e+05      10.121312   1092.007858     88.372489   \n",
      "std       13.134665  1.056530e+05       2.549995   7406.346497    404.298370   \n",
      "min       17.000000  1.376900e+04       1.000000      0.000000      0.000000   \n",
      "25%       28.000000  1.176272e+05       9.000000      0.000000      0.000000   \n",
      "50%       37.000000  1.784250e+05      10.000000      0.000000      0.000000   \n",
      "75%       47.000000  2.376285e+05      13.000000      0.000000      0.000000   \n",
      "max       90.000000  1.484705e+06      16.000000  99999.000000   4356.000000   \n",
      "\n",
      "       hours-per-week  \n",
      "count    30162.000000  \n",
      "mean        40.931238  \n",
      "std         11.979984  \n",
      "min          1.000000  \n",
      "25%         40.000000  \n",
      "50%         40.000000  \n",
      "75%         45.000000  \n",
      "max         99.000000  \n",
      "x_test has 15060 observations and 102 columns\n",
      "summary of continuous features\n",
      "                age        fnlwgt  education-num  capital-gain  capital-loss  \\\n",
      "count  15060.000000  1.506000e+04   15060.000000  15060.000000  15060.000000   \n",
      "mean      38.768327  1.896164e+05      10.112749   1120.301594     89.041899   \n",
      "std       13.380676  1.056150e+05       2.558727   7703.181842    406.283245   \n",
      "min       17.000000  1.349200e+04       1.000000      0.000000      0.000000   \n",
      "25%       28.000000  1.166550e+05       9.000000      0.000000      0.000000   \n",
      "50%       37.000000  1.779550e+05      10.000000      0.000000      0.000000   \n",
      "75%       48.000000  2.385888e+05      13.000000      0.000000      0.000000   \n",
      "max       90.000000  1.490400e+06      16.000000  99999.000000   3770.000000   \n",
      "\n",
      "       hours-per-week  \n",
      "count    15060.000000  \n",
      "mean        40.951594  \n",
      "std         12.062831  \n",
      "min          1.000000  \n",
      "25%         40.000000  \n",
      "50%         40.000000  \n",
      "75%         45.000000  \n",
      "max         99.000000  \n"
     ]
    }
   ],
   "source": [
    "print(\"x_train has\", x_train.shape[0], \"observations and\", x_train.shape[1], \"columns\")\n",
    "continuous_col = ['age', 'fnlwgt', 'education-num', 'capital-gain', 'capital-loss', 'hours-per-week']\n",
    "print(\"summary of continuous features\")\n",
    "print(x_train[continuous_col].describe())\n",
    "print(\"x_test has\", x_test.shape[0], \"observations and\", x_test.shape[1], \"columns\")\n",
    "print(\"summary of continuous features\")\n",
    "print(x_test[continuous_col].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_col = x_train.columns\n",
    "# for i in x_col:\n",
    "#     if i not in continuous_col:\n",
    "#         print(x_train[i].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.values\n",
    "y_train = y_train.values\n",
    "x_test = x_test.values\n",
    "y_test = y_test.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.2\n",
    "Derive the gradient and hessian matrix for the new E(w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our new error function $E(w) = (1/2)w^T\\Lambda w - \\Sigma_{i=1}^{n}[t_i\\ln{y_i}+(1-t_i)\\ln({1-y_i})]$ <br>\n",
    "Gradient $\\nabla E(w) = \\Lambda w - \\Sigma_{i=1}^{n}(t_i - y_i)x_i$ <br>\n",
    "$\\nabla E(w) = \\Lambda w - \\Sigma_{i=1}^{n}(t_i - \\sigma(w^Tx_i))x_i = \\Lambda w - \\Sigma_{i=1}^{n}(t_i x_i - \\sigma(w^T x_i)x_i)$ <br>\n",
    "Hessian $H(w) = \\Lambda + \\Sigma_{i=1}^{n} (\\sigma(w^T x_i)(1-\\sigma(w^T x_i)x_i)*x_i) = \\Lambda + \\Sigma_{i=1}^{n} (y_i (1-y_i) x_i x_i) = \\Lambda + \\Sigma_{i=1}^{n} x_i^Ty_i (1-y_i) x_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.3\n",
    "Create a mylogistic_l2 class <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(function):\n",
    "    return 1/(1+np.exp(-function))\n",
    "    \n",
    "class mylogistic_l2:\n",
    "    def __init__(self, reg_vec, max_iter, tol, add_intercept):\n",
    "        self.reg_vec = reg_vec\n",
    "        self.max_iter = max_iter\n",
    "        self.tol = tol\n",
    "        self.add_intercept = add_intercept\n",
    "        self.weight = None\n",
    "    \n",
    "    def error(self, y_train, y_pred):\n",
    "        lambda_weight= (1/2)*self.weight.T.dot(self.reg_lambda).dot(self.weight)\n",
    "        loss = np.sum(y_train*(np.log(y_pred)) + (1-y_train)*(np.log(1-y_pred)))\n",
    "        error = lambda_weight - loss\n",
    "        return error\n",
    "    \n",
    "    def step(self, x_train, y_train, y_pred):\n",
    "        lambda_weight = np.matmul(self.reg_lambda, self.weight)\n",
    "        error = np.matmul(x_train.T, y_train - y_pred)\n",
    "        gradient = lambda_weight - error\n",
    "    \n",
    "        matrix = np.zeros((len(y_pred), len(y_pred)))\n",
    "        np.fill_diagonal(matrix, y_pred*(1-y_pred))\n",
    "        hessian = self.reg_lambda + x_train.T.dot(matrix).dot(x_train)\n",
    "        \n",
    "        self.weight = self.weight - np.linalg.inv(hessian).dot(gradient)\n",
    "                      \n",
    "    def fit(self, x_train, y_train):\n",
    "        if self.add_intercept:\n",
    "            intercept = np.ones((x_train.shape[0],1))\n",
    "            x_train = np.hstack((x_train, intercept))\n",
    "        \n",
    "        self.reg_lambda = np.zeros((len(self.reg_vec), len(self.reg_vec)))\n",
    "        np.fill_diagonal(self.reg_lambda, self.reg_vec)\n",
    "        \n",
    "        b = np.mean(self.reg_vec)\n",
    "        tmp = np.add(np.dot(x_train.T, x_train), b*np.identity(x_train.shape[1]))\n",
    "        self.weight = np.dot(np.dot(np.linalg.inv(tmp), x_train.T), y_train)\n",
    "        \n",
    "        previous_grad = 0\n",
    "        for i in range(self.max_iter):\n",
    "            prob = np.dot(x_train, self.weight)\n",
    "            prediction = sigmoid(prob)\n",
    "            \n",
    "            prev_error = self.error(y_train, prediction)\n",
    "            self.step(x_train, y_train, prediction)\n",
    "            \n",
    "            prob = np.dot(x_train, self.weight)\n",
    "            prediction = sigmoid(prob)\n",
    "            error = self.error(y_train, prediction)\n",
    "            \n",
    "            if prev_error-error < self.tol:\n",
    "                break\n",
    "                      \n",
    "    def predict(self, x_test):\n",
    "        if self.add_intercept:\n",
    "            intercept = np.ones((x_test.shape[0],1))\n",
    "            x_test = np.hstack((x_test, intercept))\n",
    "        prob = np.dot(x_test, self.weight)\n",
    "        prediction = sigmoid(prob)\n",
    "        prediction[prediction >= 0.5] = 1\n",
    "        prediction[prediction < 0.5] = 0\n",
    "        return prediction\n",
    "    def show_weight(self):\n",
    "        return self.weight"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show the learned  𝑤  as well as test accuracy for the cases below <br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, y_pred):\n",
    "    accuracy = 0\n",
    "    for i in range(len(y_test)):\n",
    "        if y_test[i] == y_pred[i]:\n",
    "            accuracy+=1\n",
    "    return accuracy/len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Case 1: lambda = 1 for all coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_1 = np.ones((x_train.shape[1]+1,1))\n",
    "logic_1 = mylogistic_l2(reg_vec = lambda_1, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic_1.fit(x_train, y_train)\n",
    "ypred_1 = logic_1.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8480743691899071\n",
      "learned weight:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.48591297e-02],\n",
       "       [ 7.26281835e-07],\n",
       "       [ 1.85806163e-01],\n",
       "       [ 3.16590245e-04],\n",
       "       [ 6.38679434e-04],\n",
       "       [ 2.90215841e-02],\n",
       "       [ 1.89694411e-01],\n",
       "       [-4.97719501e-01],\n",
       "       [-3.10975202e-01],\n",
       "       [-1.29181491e-01],\n",
       "       [-7.94111556e-01],\n",
       "       [-6.18745003e-01],\n",
       "       [-1.17270706e+00],\n",
       "       [-4.52249247e-01],\n",
       "       [-5.44907403e-01],\n",
       "       [-3.82721832e-01],\n",
       "       [-9.99810289e-02],\n",
       "       [-2.62922225e-01],\n",
       "       [-6.29791388e-01],\n",
       "       [-4.96565839e-01],\n",
       "       [-3.08326937e-01],\n",
       "       [-1.27584811e-01],\n",
       "       [ 1.28534378e-01],\n",
       "       [ 5.87953355e-01],\n",
       "       [-2.50481306e-01],\n",
       "       [ 2.99991415e-01],\n",
       "       [-1.37579993e+00],\n",
       "       [ 6.82097029e-01],\n",
       "       [-1.00989638e-01],\n",
       "       [-1.00975740e+00],\n",
       "       [ 1.19612258e+00],\n",
       "       [ 8.38966933e-01],\n",
       "       [-9.56673066e-01],\n",
       "       [-1.50523218e+00],\n",
       "       [-1.08232391e+00],\n",
       "       [-8.14848363e-01],\n",
       "       [-8.78492150e-02],\n",
       "       [-2.46913576e-02],\n",
       "       [ 7.15174653e-01],\n",
       "       [-1.06504054e+00],\n",
       "       [-7.73348089e-01],\n",
       "       [-3.53722827e-01],\n",
       "       [-9.03671285e-01],\n",
       "       [-1.69395623e+00],\n",
       "       [ 4.29670534e-01],\n",
       "       [ 4.99488476e-01],\n",
       "       [ 2.05962313e-01],\n",
       "       [ 5.68478621e-01],\n",
       "       [-1.78947443e-01],\n",
       "       [-5.76254828e-01],\n",
       "       [-3.75781253e-01],\n",
       "       [-1.12608337e+00],\n",
       "       [-1.50192087e+00],\n",
       "       [-5.01524915e-01],\n",
       "       [ 7.47819835e-01],\n",
       "       [-1.02439618e+00],\n",
       "       [-2.92668732e-01],\n",
       "       [-6.35195701e-01],\n",
       "       [-8.96890177e-01],\n",
       "       [-4.84594618e-01],\n",
       "       [-2.09367501e+00],\n",
       "       [-1.24007039e+00],\n",
       "       [ 9.03420736e-01],\n",
       "       [ 4.04668560e-01],\n",
       "       [-5.46920552e-01],\n",
       "       [-1.31374667e+00],\n",
       "       [ 4.27865170e-01],\n",
       "       [-9.47705967e-01],\n",
       "       [-1.07395557e-01],\n",
       "       [-4.09492097e-01],\n",
       "       [ 3.77034140e-01],\n",
       "       [ 5.45751678e-01],\n",
       "       [ 5.23589384e-01],\n",
       "       [-6.70323916e-01],\n",
       "       [-1.09516216e-01],\n",
       "       [ 4.53277949e-02],\n",
       "       [-1.63971889e-01],\n",
       "       [-4.71983494e-02],\n",
       "       [-4.02281380e-03],\n",
       "       [-3.44708811e-01],\n",
       "       [ 1.03362979e-01],\n",
       "       [ 4.50497096e-01],\n",
       "       [ 8.22875669e-01],\n",
       "       [ 9.41389495e-02],\n",
       "       [ 2.92357805e-01],\n",
       "       [-3.50891475e-01],\n",
       "       [-4.39859204e-01],\n",
       "       [-4.07586321e-01],\n",
       "       [-6.90804284e-01],\n",
       "       [-4.47783816e-01],\n",
       "       [ 3.91129903e-01],\n",
       "       [ 8.03243762e-02],\n",
       "       [ 7.97357705e-02],\n",
       "       [-1.81402777e-01],\n",
       "       [-9.03628229e-02],\n",
       "       [-9.81576059e-01],\n",
       "       [-7.79910247e-02],\n",
       "       [-3.31100773e-01],\n",
       "       [-1.88816101e-01],\n",
       "       [ 2.89337136e-01],\n",
       "       [-8.34197419e-01],\n",
       "       [ 5.39068128e-01],\n",
       "       [-3.33374540e+00]])"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"test accuracy:\", accuracy(y_test, ypred_1))\n",
    "print(\"learned weight:\")\n",
    "logic_1.show_weight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Case 2: lambda = 1 for all but the intercept, no regularization for intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "lambda_2 = np.ones((x_train.shape[1],1))\n",
    "no_reg = np.zeros((1,1))\n",
    "lambda_2 = np.append(lambda_2, no_reg, axis = 0)\n",
    "logic_2 = mylogistic_l2(reg_vec = lambda_2, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic_2.fit(x_train, y_train)\n",
    "ypred_2 = logic_2.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.847808764940239\n",
      "learned weight:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.54336822e-02],\n",
       "       [ 7.50706804e-07],\n",
       "       [ 2.95324923e-01],\n",
       "       [ 3.17024478e-04],\n",
       "       [ 6.39652126e-04],\n",
       "       [ 2.94914512e-02],\n",
       "       [ 7.05717318e-01],\n",
       "       [ 1.78026502e-02],\n",
       "       [ 2.09126595e-01],\n",
       "       [ 3.82731145e-01],\n",
       "       [-2.79821710e-01],\n",
       "       [-1.04552949e-01],\n",
       "       [-9.31003049e-01],\n",
       "       [ 9.08118759e-02],\n",
       "       [-1.06210390e-01],\n",
       "       [-5.68864876e-02],\n",
       "       [ 7.06129017e-01],\n",
       "       [ 5.36014978e-01],\n",
       "       [ 1.16361326e-01],\n",
       "       [ 1.37527872e-01],\n",
       "       [-4.01951495e-01],\n",
       "       [-1.13370201e-01],\n",
       "       [-7.43801938e-02],\n",
       "       [ 6.79669927e-02],\n",
       "       [-1.95742295e-02],\n",
       "       [-1.15929725e-02],\n",
       "       [-1.15969699e+00],\n",
       "       [ 2.67049827e-01],\n",
       "       [ 2.18010722e-02],\n",
       "       [-5.26538170e-01],\n",
       "       [ 1.61452756e+00],\n",
       "       [ 1.36750998e+00],\n",
       "       [-4.92456773e-01],\n",
       "       [-1.01532721e+00],\n",
       "       [-6.05766406e-01],\n",
       "       [-3.41948994e-01],\n",
       "       [ 1.64109182e-01],\n",
       "       [ 2.28422252e-01],\n",
       "       [ 9.64856017e-01],\n",
       "       [-8.17967488e-01],\n",
       "       [-5.20782272e-01],\n",
       "       [-9.91243553e-02],\n",
       "       [-6.49283758e-01],\n",
       "       [-1.55300394e+00],\n",
       "       [ 6.78427763e-01],\n",
       "       [ 7.51030496e-01],\n",
       "       [ 4.55411798e-01],\n",
       "       [ 8.18714334e-01],\n",
       "       [ 7.31938650e-02],\n",
       "       [-4.21151177e-02],\n",
       "       [ 1.99456835e-01],\n",
       "       [-5.83542676e-01],\n",
       "       [-9.36996676e-01],\n",
       "       [ 7.53014460e-02],\n",
       "       [ 1.28789619e+00],\n",
       "       [-3.72048376e-01],\n",
       "       [ 3.94360616e-01],\n",
       "       [ 4.30693947e-02],\n",
       "       [-2.61235809e-01],\n",
       "       [ 1.95854174e-01],\n",
       "       [-4.27150728e-01],\n",
       "       [ 4.27150728e-01],\n",
       "       [ 1.00965472e+00],\n",
       "       [ 5.02337197e-01],\n",
       "       [-4.58396920e-01],\n",
       "       [-1.24053337e+00],\n",
       "       [ 5.27833699e-01],\n",
       "       [-8.67620758e-01],\n",
       "       [-2.75702542e-02],\n",
       "       [-3.15345727e-01],\n",
       "       [ 4.72832596e-01],\n",
       "       [ 6.28755385e-01],\n",
       "       [ 6.23911101e-01],\n",
       "       [-5.88433187e-01],\n",
       "       [-2.96923356e-02],\n",
       "       [ 1.24844059e-01],\n",
       "       [-1.43574429e-01],\n",
       "       [ 2.48070503e-02],\n",
       "       [ 6.14826821e-02],\n",
       "       [-2.48769642e-01],\n",
       "       [ 1.94794455e-01],\n",
       "       [ 5.25952046e-01],\n",
       "       [ 9.31972681e-01],\n",
       "       [ 1.87606692e-01],\n",
       "       [ 3.79606530e-01],\n",
       "       [-2.87259337e-01],\n",
       "       [-3.10421302e-01],\n",
       "       [-3.32413818e-01],\n",
       "       [-6.50777756e-01],\n",
       "       [-3.81261235e-01],\n",
       "       [ 4.89030076e-01],\n",
       "       [ 1.76281854e-01],\n",
       "       [ 1.74545517e-01],\n",
       "       [-7.36414561e-02],\n",
       "       [-3.10934765e-02],\n",
       "       [-8.98503738e-01],\n",
       "       [ 6.72286166e-03],\n",
       "       [-2.72168680e-01],\n",
       "       [-1.23870297e-01],\n",
       "       [ 3.96789072e-01],\n",
       "       [-7.54273374e-01],\n",
       "       [ 6.10526925e-01],\n",
       "       [-8.88722778e+00]])"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"test accuracy:\", accuracy(y_test, ypred_2))\n",
    "print(\"learned weight:\")\n",
    "logic_2.show_weight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Case 3: lambda = 1 for numerical-valued features, lambda = 0.5 for binary-valued features, no regularization for intercept term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_cnt = 102-6\n",
    "numerical = np.ones((6,1))\n",
    "binary = np.full((binary_cnt,1), 0.5)\n",
    "no_reg = np.zeros((1,1))\n",
    "lambda_3 = np.append(numerical, binary, axis = 0)\n",
    "lambda_3 = np.append(lambda_3, no_reg, axis = 0)\n",
    "\n",
    "logic_3 = mylogistic_l2(reg_vec = lambda_3, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic_3.fit(x_train, y_train)\n",
    "ypred_3 = logic_3.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.847675962815405\n",
      "learned weight:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 2.54757306e-02],\n",
       "       [ 7.51944312e-07],\n",
       "       [ 3.19092342e-01],\n",
       "       [ 3.17319913e-04],\n",
       "       [ 6.40115459e-04],\n",
       "       [ 2.95135990e-02],\n",
       "       [ 7.66990116e-01],\n",
       "       [ 7.62915468e-02],\n",
       "       [ 2.68338059e-01],\n",
       "       [ 4.43128006e-01],\n",
       "       [-2.20821080e-01],\n",
       "       [-4.63422171e-02],\n",
       "       [-1.28758443e+00],\n",
       "       [ 2.18992474e-01],\n",
       "       [-2.26138746e-03],\n",
       "       [ 2.18816240e-02],\n",
       "       [ 9.74981438e-01],\n",
       "       [ 7.54034099e-01],\n",
       "       [ 2.92224729e-01],\n",
       "       [ 2.93070077e-01],\n",
       "       [-4.19612079e-01],\n",
       "       [-1.04346489e-01],\n",
       "       [-1.12963414e-01],\n",
       "       [-3.78240639e-02],\n",
       "       [ 3.76517833e-02],\n",
       "       [-7.30516160e-02],\n",
       "       [-2.08394382e+00],\n",
       "       [ 1.86338344e-01],\n",
       "       [ 5.48283060e-02],\n",
       "       [-5.72016449e-01],\n",
       "       [ 1.82571092e+00],\n",
       "       [ 1.39641685e+00],\n",
       "       [-5.47067011e-01],\n",
       "       [-1.05936560e+00],\n",
       "       [-6.55642137e-01],\n",
       "       [-3.88036577e-01],\n",
       "       [ 2.36234437e-01],\n",
       "       [ 3.00253515e-01],\n",
       "       [ 1.03825743e+00],\n",
       "       [-7.52669826e-01],\n",
       "       [-4.53424433e-01],\n",
       "       [-2.69071876e-02],\n",
       "       [-5.82347589e-01],\n",
       "       [-2.00233623e+00],\n",
       "       [ 7.51037215e-01],\n",
       "       [ 8.27361950e-01],\n",
       "       [ 5.28329990e-01],\n",
       "       [ 8.95057944e-01],\n",
       "       [ 1.45241823e-01],\n",
       "       [-8.34438329e-02],\n",
       "       [ 2.32699099e-01],\n",
       "       [-5.92702349e-01],\n",
       "       [-9.22764465e-01],\n",
       "       [ 1.11240579e-01],\n",
       "       [ 1.25497097e+00],\n",
       "       [-3.83664192e-01],\n",
       "       [ 4.13058381e-01],\n",
       "       [ 4.13741738e-02],\n",
       "       [-2.63868162e-01],\n",
       "       [ 1.93099799e-01],\n",
       "       [-4.29102318e-01],\n",
       "       [ 4.29102318e-01],\n",
       "       [ 1.18913496e+00],\n",
       "       [ 5.50823608e-01],\n",
       "       [-4.76703527e-01],\n",
       "       [-1.45906500e+00],\n",
       "       [ 5.82266265e-01],\n",
       "       [-1.06198153e+00],\n",
       "       [-9.41602947e-03],\n",
       "       [-3.18451359e-01],\n",
       "       [ 5.24213675e-01],\n",
       "       [ 7.29262556e-01],\n",
       "       [ 6.74417681e-01],\n",
       "       [-6.38233984e-01],\n",
       "       [-9.70381891e-03],\n",
       "       [ 1.74243000e-01],\n",
       "       [-2.36216831e-01],\n",
       "       [ 3.80746788e-02],\n",
       "       [ 1.00364760e-01],\n",
       "       [-2.47188687e-01],\n",
       "       [ 2.38206931e-01],\n",
       "       [ 6.41987678e-01],\n",
       "       [ 1.00609330e+00],\n",
       "       [ 2.33159551e-01],\n",
       "       [ 4.22778119e-01],\n",
       "       [-3.53092076e-01],\n",
       "       [-2.90744305e-01],\n",
       "       [-3.80716117e-01],\n",
       "       [-9.62423327e-01],\n",
       "       [-4.49692076e-01],\n",
       "       [ 5.13214009e-01],\n",
       "       [ 2.19832865e-01],\n",
       "       [ 2.27002285e-01],\n",
       "       [-5.01169774e-02],\n",
       "       [-1.79082779e-02],\n",
       "       [-9.59642147e-01],\n",
       "       [ 1.67395337e-02],\n",
       "       [-3.27257717e-01],\n",
       "       [-1.39435387e-01],\n",
       "       [ 4.28358923e-01],\n",
       "       [-8.46069991e-01],\n",
       "       [ 7.51083220e-01],\n",
       "       [-9.31135040e+00]])"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"test accuracy:\", accuracy(y_test, ypred_3))\n",
    "print(\"learned weight:\")\n",
    "logic_3.show_weight()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.4\n",
    "Split the training data into subtraining (90%) and tuning (10%) to search for the best hyperparameters <br>\n",
    "Set the regularization coefficient for the constant term to zero. Allow different regularizations for continuous-valued and binary-valued features <br>\n",
    "Let  𝑎1  and  𝑎2  denote the regularization coefficients for continuous-valued and binary-valued features <br>\n",
    "Search the best  𝑎1  and  𝑎2  and report the test accuracy using the best hyper-parameters. You should follow the following procedure to search for the best hyperparameters <br>\n",
    "\n",
    "1. Choose a set of grids among a reasonable range. For example, 10 grids in [0.01, 100] \n",
    "2. Conduct grid search with the constraint that  𝑎1=𝑎2 . Record the best value  𝑎∗1  and  𝑎∗2 \n",
    "3. Fix  𝑎1=𝑎∗1 , and search  𝑎2  for the best value, call the result the new  𝑎∗2 \n",
    "4. Fix  𝑎2=𝑎∗2 , and search  𝑎1  for the best value\n",
    "5. Report the selected  𝑎1  and  𝑎2 \n",
    "6. Train a model using the selected hyper-parameters, and report the test accuracy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = int(np.around(len(x_train)*0.9))\n",
    "x_subtrain = x_train[0:index]\n",
    "x_tuning = x_train[index:]\n",
    "y_subtrain = y_train[0:index]\n",
    "y_tuning = y_train[index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 1\n",
    "tuning = [0.001, 0.005, 0.01, 0.05, 0.1, 0.5, 1, 10, 50, 100]\n",
    "tune_accuracy = []\n",
    "# step 2\n",
    "for i in tuning:\n",
    "    con_binary = np.full((x_subtrain.shape[1],1), i)\n",
    "    no_reg = np.zeros((1,1))\n",
    "    lambda_t1 = np.append(con_binary, no_reg, axis = 0)\n",
    "\n",
    "    logic_t1 = mylogistic_l2(reg_vec = lambda_t1, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic_t1.fit(x_subtrain, y_subtrain)\n",
    "    ypred_t1 = logic_t1.predict(x_tuning)\n",
    "    tune_accuracy.append(accuracy(ypred_t1, y_tuning))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_coefficient = tuning[np.argmax(tune_accuracy)]\n",
    "# step 3\n",
    "tune_a2_acc = []\n",
    "for i in tuning:\n",
    "    binary_cnt = 102-6\n",
    "    numerical = np.full((6,1), best_coefficient)\n",
    "    binary = np.full((binary_cnt,1), i)\n",
    "    no_reg = np.zeros((1,1))\n",
    "    lambda_t2 = np.append(numerical, binary, axis = 0)\n",
    "    lambda_t2 = np.append(lambda_t2, no_reg, axis = 0)\n",
    "\n",
    "    logic_t2 = mylogistic_l2(reg_vec = lambda_t2, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic_t2.fit(x_subtrain, y_subtrain)\n",
    "    ypred_t2 = logic_t2.predict(x_tuning)\n",
    "    tune_a2_acc.append(accuracy(ypred_t2, y_tuning))\n",
    "best_a2 = tuning[np.argmax(tune_a2_acc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "selected a1: 0.001\n",
      "selected a2: 0.001\n"
     ]
    }
   ],
   "source": [
    "# step 4\n",
    "tune_a1_acc = []\n",
    "for i in tuning:\n",
    "    binary_cnt = 102-6\n",
    "    numerical = np.full((6,1), i)\n",
    "    binary = np.full((binary_cnt,1), best_a2)\n",
    "    no_reg = np.zeros((1,1))\n",
    "    lambda_t3 = np.append(numerical, binary, axis = 0)\n",
    "    lambda_t3 = np.append(lambda_t3, no_reg, axis = 0)\n",
    "\n",
    "    logic_t3 = mylogistic_l2(reg_vec = lambda_t3, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "    logic_t3.fit(x_subtrain, y_subtrain)\n",
    "    ypred_t3 = logic_t3.predict(x_tuning)\n",
    "    tune_a1_acc.append(accuracy(ypred_t3, y_tuning))\n",
    "best_a1 = tuning[np.argmax(tune_a1_acc)]\n",
    "# step 5\n",
    "print(\"selected a1:\", best_a1)\n",
    "print(\"selected a2:\", best_a2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accuracy: 0.8476095617529881\n"
     ]
    }
   ],
   "source": [
    "# step 6\n",
    "binary_cnt = 102-6\n",
    "numerical = np.full((6,1), best_a1)\n",
    "binary = np.full((binary_cnt,1), best_a2)\n",
    "no_reg = np.zeros((1,1))\n",
    "lambda_t4 = np.append(numerical, binary, axis = 0)\n",
    "lambda_t4 = np.append(lambda_t4, no_reg, axis = 0)\n",
    "\n",
    "logic_t4 = mylogistic_l2(reg_vec = lambda_t4, max_iter = 1000, tol = 1e-5, add_intercept = True)\n",
    "logic_t4.fit(x_train, y_train)\n",
    "ypred_t4 = logic_t4.predict(x_test)\n",
    "print(\"test accuracy:\", accuracy(ypred_t4, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1.5\n",
    "Use sklearn.linear_model.LogisticRegression to train and test the model (including hyperparameter tuning) <br>\n",
    "Compare the estimated parameters and test accuracy with those from your own models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n"
     ]
    }
   ],
   "source": [
    "logic_c = [0.001, 0.05, 0.1, 0.5, 1, 5, 10, 50, 100]\n",
    "sk_tune_acc = []\n",
    "for i in tuning:\n",
    "    logic_sk = LogisticRegression(C = i, fit_intercept=True, tol = 1e-5, max_iter = 1000).fit(x_subtrain, y_subtrain.ravel())\n",
    "    logic_sk.predict(x_tuning)\n",
    "    sk_tune_acc.append(logic_sk.score(x_tuning, y_tuning.ravel()))\n",
    "best_sk_coef = tuning[np.argmax(sk_tune_acc)]\n",
    "\n",
    "logic_sk = LogisticRegression(C = best_sk_coef, fit_intercept=True).fit(x_train, y_train.ravel())\n",
    "sk_pred = logic_sk.predict(x_test)\n",
    "test_acc = logic_sk.score(x_test, y_test.ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "****** my model ******\n",
      "coefficient for continuous features: 0.001\n",
      "coefficient for binary features: 0.001\n",
      "test accuracy: 0.8476095617529881\n",
      "****** sklearn model ******\n",
      "coefficient: 0.01\n",
      "test accuracy: 0.7932934926958831\n"
     ]
    }
   ],
   "source": [
    "print(\"****** my model ******\")\n",
    "print(\"coefficient for continuous features:\", best_a1)\n",
    "print(\"coefficient for binary features:\", best_a2)\n",
    "print(\"test accuracy:\", accuracy(ypred_t4, y_test))\n",
    "print(\"****** sklearn model ******\")\n",
    "print(\"coefficient:\", best_sk_coef)\n",
    "print(\"test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The best parameter $\\lambda$ for sklearn model is 0.01, while the best parameter for continuous features and binary features for my own model are both 0.001. <br>\n",
    "The test accuracy of my own model(0.8476) is better than the test accuracy of sklearn model(0.7933)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
